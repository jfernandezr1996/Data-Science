{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de la técnica `stacking` usando el paquete `vecstack`\n",
    "---\n",
    "\n",
    "A partir de la técnica **stacking** se construyen múltiples modelos de distinto tipo y un modelo supervisor que es entrenado para combinar de la mejor forma posible las predicciones obtenidas a partir de los modelos primarios.\n",
    "\n",
    "Como caso de uso se utilizará el dataset `iris` como simple dataset de clasificación multiclase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de las librerias necesarias\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from vecstack import stacking\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura del set de datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "69                5.6               2.5                3.9               1.1\n",
       "18                5.7               3.8                1.7               0.3\n",
       "7                 5.0               3.4                1.5               0.2\n",
       "53                5.5               2.3                4.0               1.3\n",
       "54                6.5               2.8                4.6               1.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X, columns=iris.feature_names)\n",
    "y = pd.DataFrame(y, columns=['target'])\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partición entrenamiento y test\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de los modelos de primer nivel para aplicar la técnica stacking posteriormente\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    KNeighborsClassifier(n_neighbors=5,\n",
    "                        n_jobs=-1),\n",
    "        \n",
    "    RandomForestClassifier(random_state=0, n_jobs=-1, \n",
    "                           n_estimators=100, max_depth=3),\n",
    "        \n",
    "    XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                  n_estimators=100, max_depth=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos presentan una serie de varlores en sus hiperparámetros. Habría que realizar un análisis previo de dicha búsqueda óptima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones para los modelos definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [3]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [KNeighborsClassifier]\n",
      "    fold  0:  [1.00000000]\n",
      "    fold  1:  [0.92592593]\n",
      "    fold  2:  [0.96153846]\n",
      "    fold  3:  [1.00000000]\n",
      "    ----\n",
      "    MEAN:     [0.97186610] + [0.03082285]\n",
      "    FULL:     [0.97142857]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.96296296]\n",
      "    fold  1:  [0.92592593]\n",
      "    fold  2:  [0.92307692]\n",
      "    fold  3:  [0.96000000]\n",
      "    ----\n",
      "    MEAN:     [0.94299145] + [0.01854705]\n",
      "    FULL:     [0.94285714]\n",
      "\n",
      "model  2:     [XGBClassifier]\n",
      "    fold  0:  [0.96296296]\n",
      "    fold  1:  [0.96296296]\n",
      "    fold  2:  [0.92307692]\n",
      "    fold  3:  [0.92000000]\n",
      "    ----\n",
      "    MEAN:     [0.94225071] + [0.02074080]\n",
      "    FULL:     [0.94285714]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S_train, S_test = stacking(models, X_train, y_train, X_test, regression=False, mode='oof_pred_bag', needs_proba=False,\n",
    "                           save_dir=None, metric=accuracy_score, n_folds=4, stratified=True, shuffle=True, \n",
    "                           random_state=0, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar el ajuste excesivo, la validación cruzada se suele utilizar para predecir la parte OOB (no disponible) del conjunto de entrenamiento. Es decir, al definir el número de pliegues el proceso es el siguiente:\n",
    "- Dividimos nuestro set de datos en 4 pliegues.\n",
    "- Para cada pliegue, tomamos los tres pliegues restantes y definimos nuestro modelo. La medida de evaluación en el conjunto train la hacemos realizando las predicciones sobre el pliegue tomado. \n",
    "- Posteriormente, realizamos las predicciones sobre el set de datos destinado para el test.\n",
    "- Una vez que hemos hecho este proceso en cada pliege, obtenemos la media de la precisión alcanzada en cada uno de ellos para obtener una medida global del método.\n",
    "\n",
    "La función tiene varias entradas:\n",
    "- **models** : los modelos de primer nivel que definimos anteriormente\n",
    "- **X_train, y_train, X_test** : nuestros datos\n",
    "- **regression** : booleano que indica si queremos usar la función de regresión. En nuestro caso puesto en Falso ya que esta es una clasificación.\n",
    "- **mode**: utilizando la descripción anterior de fuera de pliegue durante la validación cruzada\n",
    "- **needs_proba** : booleano que indica si necesita las probabilidades de las etiquetas de clase\n",
    "- **save_dir** : guarda el resultado en el directorio Boolean\n",
    "- **metric** : qué métrica de evaluación usar (importamos la puntuación de precisión al principio)\n",
    "- **n_folds** : cuántos pliegues usar para la validación cruzada\n",
    "- **stratified** : si se debe utilizar la validación cruzada estratificada\n",
    "- **shuffle** : si se barajan los datos\n",
    "- **random_state** : establecer un estado aleatorio para reproducibilidad\n",
    "- **verbose** : 2 aquí se refiere a imprimir toda la información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones finales. Ajustar los modelos anteriores\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo lo que queda por hacer es ajustar los modelos de segundo nivel de nuestra elección en nuestras predicciones para hacer nuestras predicciones finales. En nuestro caso, vamos a utilizar un clasificador XGBoost. Este paso no es significativamente diferente de un ajuste y predicción regular en sklearn, excepto por el hecho de que en lugar de usar X_train para entrenar a nuestro modelo, estamos usando nuestras predicciones S_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión alcanzada: 0.97777778\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                      n_estimators=100, max_depth=3)\n",
    "    \n",
    "model = model.fit(S_train, y_train)\n",
    "y_pred = model.predict(S_test)\n",
    "print('Precisión alcanzada: %.8f' % accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
